#!/usr/bin/env python3
"""
Exerc√≠cio 13: Consultar tabela particionada
- Fazer consultas eficientes na tabela particionada
- Demonstrar partition pruning
- Comparar performance com e sem filtros de parti√ß√£o
"""

import sys
import os
sys.path.append(os.path.dirname(__file__))

try:
    from config import create_spark_session
    from pyspark.sql import functions as F
except ImportError as e:
    print(f"‚ùå Erro ao importar depend√™ncias: {e}")
    print("üí° Certifique-se de que o PySpark est√° instalado: pip install pyspark")
    sys.exit(1)

def main():
    """
    Fun√ß√£o principal do exerc√≠cio 13
    """
    spark = None
    try:
        print("üîç Exerc√≠cio 13: Consultar tabela particionada")
        print("-" * 50)
        
        # Criar sess√£o Spark
        spark = create_spark_session("Exercicio_13_Query_Partitioned")
        
        # Verificar se a tabela particionada existe
        try:
            count = spark.sql("SELECT COUNT(*) FROM iceberg.exercicios.funcionarios_por_depto").collect()[0][0]
            print(f"‚úÖ Tabela funcionarios_por_depto encontrada com {count} registros")
        except Exception as e:
            print(f"‚ö†Ô∏è Tabela funcionarios_por_depto n√£o encontrada: {e}")
            print("üí° Execute primeiro os exerc√≠cios 11 e 12 para criar e popular a tabela")
            return False
        
        print("\n1Ô∏è‚É£ Consulta com partition pruning - departamento espec√≠fico:")
        # Esta consulta √© eficiente porque usa a coluna de parti√ß√£o
        ti_query = spark.sql("""
            SELECT nome, cargo, salario
            FROM iceberg.exercicios.funcionarios_por_depto
            WHERE departamento = 'TI'
            ORDER BY salario DESC
        """)
        
        print("üë• Funcion√°rios do departamento de TI:")
        ti_query.show()
        
        # Mostrar plano de execu√ß√£o (se dispon√≠vel)
        print("\nüìã Plano de execu√ß√£o da consulta:")
        try:
            ti_query.explain()
        except Exception as e:
            print(f"‚ö†Ô∏è N√£o foi poss√≠vel mostrar o plano: {e}")
        
        print("\n2Ô∏è‚É£ Consulta com m√∫ltiplas parti√ß√µes:")
        # Consultar m√∫ltiplos departamentos
        multi_dept = spark.sql("""
            SELECT departamento, nome, cargo, salario
            FROM iceberg.exercicios.funcionarios_por_depto
            WHERE departamento IN ('TI', 'Vendas', 'Marketing')
            ORDER BY departamento, salario DESC
        """)
        
        print("üë• Funcion√°rios de TI, Vendas e Marketing:")
        multi_dept.show()
        
        print("\n3Ô∏è‚É£ Consulta sem filtro de parti√ß√£o:")
        # Esta consulta l√™ todas as parti√ß√µes
        high_salaries = spark.sql("""
            SELECT nome, departamento, cargo, salario
            FROM iceberg.exercicios.funcionarios_por_depto
            WHERE salario > 8000
            ORDER BY salario DESC
        """)
        
        print("üí∞ Funcion√°rios com sal√°rio > R$ 8000:")
        high_salaries.show()
        
        print("\n4Ô∏è‚É£ Agrega√ß√µes por parti√ß√£o:")
        # Estat√≠sticas por departamento (muito eficiente)
        stats_by_dept = spark.sql("""
            SELECT 
                departamento,
                COUNT(*) as total_funcionarios,
                AVG(salario) as salario_medio,
                MIN(salario) as salario_minimo,
                MAX(salario) as salario_maximo,
                STDDEV(salario) as desvio_padrao
            FROM iceberg.exercicios.funcionarios_por_depto
            GROUP BY departamento
            ORDER BY salario_medio DESC
        """)
        
        print("üìä Estat√≠sticas por departamento:")
        stats_by_dept.show()
        
        print("\n5Ô∏è‚É£ Consulta complexa com join interno:")
        # Simular join com outra tabela (usando a pr√≥pria tabela para demonstra√ß√£o)
        spark.sql("""
            CREATE OR REPLACE TEMPORARY VIEW dept_summary AS
            SELECT 
                departamento,
                AVG(salario) as salario_medio_dept
            FROM iceberg.exercicios.funcionarios_por_depto
            GROUP BY departamento
        """)
        
        complex_query = spark.sql("""
            SELECT 
                f.nome,
                f.departamento,
                f.cargo,
                f.salario,
                d.salario_medio_dept,
                CASE 
                    WHEN f.salario > d.salario_medio_dept THEN 'Acima da M√©dia'
                    ELSE 'Abaixo da M√©dia'
                END as posicao_salarial
            FROM iceberg.exercicios.funcionarios_por_depto f
            JOIN dept_summary d ON f.departamento = d.departamento
            WHERE f.departamento = 'TI'
            ORDER BY f.salario DESC
        """)
        
        print("üéØ An√°lise salarial do departamento de TI:")
        complex_query.show()
        
        print("\n6Ô∏è‚É£ Window functions com parti√ß√£o:")
        # Usar window functions para ranking
        ranking_query = spark.sql("""
            SELECT 
                nome,
                departamento,
                cargo,
                salario,
                ROW_NUMBER() OVER (PARTITION BY departamento ORDER BY salario DESC) as ranking_dept,
                DENSE_RANK() OVER (ORDER BY salario DESC) as ranking_geral
            FROM iceberg.exercicios.funcionarios_por_depto
        """)
        
        print("üèÜ Ranking salarial por departamento:")
        ranking_query.show()
        
        print("\n7Ô∏è‚É£ Consulta de performance - contagem por departamento:")
        # Esta √© muito r√°pida devido ao particionamento
        import time
        start_time = time.time()
        
        count_by_dept = spark.sql("""
            SELECT departamento, COUNT(*) as funcionarios
            FROM iceberg.exercicios.funcionarios_por_depto
            GROUP BY departamento
            ORDER BY funcionarios DESC
        """)
        
        count_by_dept.show()
        end_time = time.time()
        
        print(f"‚è±Ô∏è Tempo de execu√ß√£o: {end_time - start_time:.3f} segundos")
        
        print("\n8Ô∏è‚É£ Filtros avan√ßados com m√∫ltiplas condi√ß√µes:")
        advanced_filter = spark.sql("""
            SELECT 
                departamento,
                nome,
                cargo,
                salario
            FROM iceberg.exercicios.funcionarios_por_depto
            WHERE departamento = 'TI' 
            AND salario BETWEEN 6000 AND 9000
            AND cargo LIKE '%Senior%' OR cargo LIKE '%Lead%'
            ORDER BY salario DESC
        """)
        
        print("üéØ Filtros avan√ßados - TI com sal√°rio entre 6k-9k e cargo senior/lead:")
        advanced_filter.show()
        
        print("‚úÖ Exerc√≠cio 13 conclu√≠do com sucesso!")
        print("üîç Demonstramos consultas eficientes em tabela particionada")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro no exerc√≠cio 13: {e}")
        return False
    finally:
        if spark:
            spark.stop()

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)