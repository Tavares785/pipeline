#!/usr/bin/env python3
"""
Exerc√≠cio 14: Demonstrar time travel no Iceberg
- Usar recursos de time travel para acessar vers√µes hist√≥ricas
- Visualizar snapshots da tabela
- Fazer consultas em pontos espec√≠ficos no tempo
"""

import sys
import os
sys.path.append(os.path.dirname(__file__))

try:
    from config import create_spark_session
    from pyspark.sql import functions as F
    import time
    from datetime import datetime
except ImportError as e:
    print(f"‚ùå Erro ao importar depend√™ncias: {e}")
    print("üí° Certifique-se de que o PySpark est√° instalado: pip install pyspark")
    sys.exit(1)

def main():
    """
    Fun√ß√£o principal do exerc√≠cio 14
    """
    spark = None
    try:
        print("‚è∞ Exerc√≠cio 14: Time Travel no Iceberg")
        print("-" * 50)
        
        # Criar sess√£o Spark
        spark = create_spark_session("Exercicio_14_Time_Travel")
        
        # Verificar se a tabela existe
        try:
            spark.sql("SELECT COUNT(*) FROM iceberg.exercicios.funcionarios").show()
            print("‚úÖ Tabela funcionarios encontrada")
        except Exception as e:
            print(f"‚ö†Ô∏è Tabela funcionarios n√£o encontrada: {e}")
            print("üí° Execute primeiro os exerc√≠cios 4, 5 e 6 para criar a tabela")
            return False
        
        print("\n1Ô∏è‚É£ Visualizando snapshots da tabela:")
        try:
            # Mostrar hist√≥rico de snapshots
            snapshots = spark.sql("SELECT * FROM iceberg.exercicios.funcionarios.snapshots")
            print("üì∑ Hist√≥rico de snapshots:")
            snapshots.select(
                "snapshot_id", 
                "timestamp_ms",
                "operation",
                "summary"
            ).show(truncate=False)
            
            # Guardar informa√ß√µes dos snapshots para uso posterior
            snapshot_list = snapshots.select("snapshot_id", "timestamp_ms").collect()
            
        except Exception as e:
            print(f"‚ö†Ô∏è N√£o foi poss√≠vel acessar snapshots: {e}")
            snapshot_list = []
        
        print("\n2Ô∏è‚É£ Estado atual da tabela:")
        current_data = spark.sql("""
            SELECT id, nome, departamento, cargo, salario 
            FROM iceberg.exercicios.funcionarios 
            ORDER BY id
        """)
        current_data.show()
        current_count = current_data.count()
        print(f"üìä Total atual de registros: {current_count}")
        
        print("\n3Ô∏è‚É£ Fazendo uma modifica√ß√£o para criar novo snapshot:")
        # Adicionar um funcion√°rio tempor√°rio para criar um novo snapshot
        current_time = datetime.now()
        print(f"üïê Timestamp atual: {current_time}")
        
        spark.sql("""
            INSERT INTO iceberg.exercicios.funcionarios 
            VALUES (999, 'Funcion√°rio Tempor√°rio', 'Teste', 'Tempor√°rio', 1000.0)
        """)
        
        print("‚úÖ Funcion√°rio tempor√°rio adicionado")
        
        # Pequena pausa para garantir timestamps diferentes
        time.sleep(2)
        
        print("\n4Ô∏è‚É£ Verificando novo estado:")
        new_data = spark.sql("""
            SELECT id, nome, departamento, cargo, salario 
            FROM iceberg.exercicios.funcionarios 
            ORDER BY id
        """)
        new_count = new_data.count()
        print(f"üìä Total ap√≥s inser√ß√£o: {new_count}")
        
        print("\n5Ô∏è‚É£ Atualizando snapshots:")
        try:
            updated_snapshots = spark.sql("SELECT * FROM iceberg.exercicios.funcionarios.snapshots")
            print("üì∑ Snapshots atualizados:")
            updated_snapshots.select(
                "snapshot_id", 
                F.from_unixtime(F.col("timestamp_ms")/1000).alias("timestamp"),
                "operation"
            ).orderBy("timestamp_ms").show()
            
            # Pegar o snapshot mais recente e o anterior
            recent_snapshots = updated_snapshots.select("snapshot_id", "timestamp_ms")\
                                              .orderBy(F.desc("timestamp_ms"))\
                                              .limit(2).collect()
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao acessar snapshots: {e}")
            recent_snapshots = []
        
        if len(recent_snapshots) >= 2:
            latest_snapshot = recent_snapshots[0]["snapshot_id"]
            previous_snapshot = recent_snapshots[1]["snapshot_id"]
            
            print(f"\n6Ô∏è‚É£ Time Travel - consultando snapshot anterior:")
            print(f"üì∑ Snapshot anterior: {previous_snapshot}")
            
            try:
                # Consultar dados do snapshot anterior
                previous_data = spark.sql(f"""
                    SELECT id, nome, departamento, cargo, salario 
                    FROM iceberg.exercicios.funcionarios
                    VERSION AS OF {previous_snapshot}
                    ORDER BY id
                """)
                
                print("üìä Dados do snapshot anterior:")
                previous_data.show()
                previous_count = previous_data.count()
                print(f"üìà Registros no snapshot anterior: {previous_count}")
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao consultar snapshot anterior: {e}")
                print("üí° Time travel pode n√£o estar dispon√≠vel neste ambiente")
        
        print("\n7Ô∏è‚É£ Time Travel usando timestamp:")
        try:
            # Calcular timestamp de 5 minutos atr√°s
            five_minutes_ago = int((current_time.timestamp() - 300) * 1000)
            
            timestamp_query = spark.sql(f"""
                SELECT COUNT(*) as registros
                FROM iceberg.exercicios.funcionarios
                TIMESTAMP AS OF {five_minutes_ago}
            """)
            
            print(f"üìä Registros h√° 5 minutos:")
            timestamp_query.show()
            
        except Exception as e:
            print(f"‚ö†Ô∏è Time travel por timestamp n√£o dispon√≠vel: {e}")
        
        print("\n8Ô∏è‚É£ Comparando vers√µes:")
        # Mostrar diferen√ßa entre vers√µes
        try:
            current_ids = spark.sql("SELECT id FROM iceberg.exercicios.funcionarios").rdd.map(lambda r: r[0]).collect()
            
            if len(recent_snapshots) >= 2:
                previous_ids = spark.sql(f"""
                    SELECT id FROM iceberg.exercicios.funcionarios
                    VERSION AS OF {previous_snapshot}
                """).rdd.map(lambda r: r[0]).collect()
                
                new_ids = set(current_ids) - set(previous_ids)
                print(f"üÜï IDs adicionados na √∫ltima vers√£o: {new_ids}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Erro na compara√ß√£o: {e}")
        
        print("\n9Ô∏è‚É£ Limpeza - removendo funcion√°rio tempor√°rio:")
        spark.sql("DELETE FROM iceberg.exercicios.funcionarios WHERE id = 999")
        print("‚úÖ Funcion√°rio tempor√°rio removido")
        
        print("\nüîü Verificando snapshots finais:")
        try:
            final_snapshots = spark.sql("SELECT * FROM iceberg.exercicios.funcionarios.snapshots")
            final_count = final_snapshots.count()
            print(f"üì∑ Total de snapshots: {final_count}")
            
            print("üìä √öltimos 3 snapshots:")
            final_snapshots.select(
                "snapshot_id",
                F.from_unixtime(F.col("timestamp_ms")/1000).alias("timestamp"),
                "operation"
            ).orderBy(F.desc("timestamp_ms")).limit(3).show()
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao verificar snapshots finais: {e}")
        
        print("‚úÖ Exerc√≠cio 14 conclu√≠do com sucesso!")
        print("‚è∞ Demonstramos recursos de time travel do Iceberg")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro no exerc√≠cio 14: {e}")
        return False
    finally:
        if spark:
            spark.stop()

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)