{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook: exercicios_lab.ipynb\n",
    "\n",
    "# Célula 2: Criar SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Lab Iceberg Exercises\") \\\n",
    "    .config(\"spark.sql.catalog.lab\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.lab.type\", \"hive\") \\\n",
    "    .config(\"spark.sql.catalog.lab.uri\", \"thrift://localhost:9083\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark session criada!\")\n",
    "\n",
    "# Célula 3: Exercício 2 - Criar DataFrame e salvar CSV\n",
    "data = [(1, \"Alice\"), (2, \"Bob\"), (3, \"Carol\")]\n",
    "columns = [\"id\", \"nome\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.write.mode(\"overwrite\").csv(\"hdfs://namenode:9000/data/ex1.csv\", header=True)\n",
    "print(\"CSV salvo no HDFS\")\n",
    "\n",
    "# Célula 4: Exercício 3 - Ler CSV do HDFS\n",
    "df_read = spark.read.csv(\"hdfs://namenode:9000/data/ex1.csv\", header=True, inferSchema=True)\n",
    "df_read.show()\n",
    "\n",
    "# Célula 5: Exercício 4 - Criar namespace Iceberg\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS lab.db\")\n",
    "\n",
    "# Célula 6: Exercício 5 - Criar tabela Iceberg\n",
    "spark.sql(\"CREATE TABLE lab.db.pessoas (id INT, nome STRING) USING ICEBERG\")\n",
    "\n",
    "# Célula 7: Exercício 6 - Inserir dados\n",
    "spark.sql(\"INSERT INTO lab.db.pessoas VALUES (1,'Alice'), (2,'Bob'), (3,'Carol')\")\n",
    "\n",
    "# Célula 8: Exercício 7 - Ler tabela Iceberg\n",
    "spark.sql(\"SELECT * FROM lab.db.pessoas\").show()\n",
    "\n",
    "# Célula 9: Exercício 8 - Contar registros\n",
    "spark.sql(\"SELECT COUNT(*) AS total FROM lab.db.pessoas\").show()\n",
    "\n",
    "# Célula 10: Exercício 9 - Atualizar um registro\n",
    "spark.sql(\"UPDATE lab.db.pessoas SET nome = 'Alice Silva' WHERE nome = 'Alice'\")\n",
    "\n",
    "# Célula 11: Exercício 10 - Deletar um registro\n",
    "spark.sql(\"DELETE FROM lab.db.pessoas WHERE nome = 'Bob'\")\n",
    "\n",
    "# Célula 12: Exercício 11 - Criar tabela particionada\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE lab.db.vendas (\n",
    "    id INT,\n",
    "    valor DOUBLE,\n",
    "    ano INT\n",
    ") USING ICEBERG\n",
    "PARTITIONED BY (ano)\n",
    "\"\"\")\n",
    "\n",
    "# Célula 13: Exercício 12 - Inserir dados particionados\n",
    "spark.sql(\"\"\"\n",
    "INSERT INTO lab.db.vendas VALUES\n",
    "(1, 100.0, 2022),\n",
    "(2, 200.0, 2023),\n",
    "(3, 300.0, 2023),\n",
    "(4, 400.0, 2024)\n",
    "\"\"\")\n",
    "\n",
    "# Célula 14: Exercício 13 - Consultar apenas um particionamento\n",
    "spark.sql(\"SELECT * FROM lab.db.vendas WHERE ano = 2023\").show()\n",
    "\n",
    "# Célula 15: Exercício 14 - Ver metadados da tabela\n",
    "spark.sql(\"DESCRIBE HISTORY lab.db.vendas\").show()\n",
    "spark.sql(\"DESCRIBE DETAIL lab.db.vendas\").show()\n",
    "\n",
    "# Célula 16: Exercício 15 - Criar tabela Iceberg a partir de DataFrame\n",
    "df2 = spark.createDataFrame([(10, \"Produto A\"), (20, \"Produto B\")], [\"id\", \"nome\"])\n",
    "df2.writeTo(\"lab.db.tabela_df\").createOrReplace()\n",
    "\n",
    "# Célula 17: Exercício 16 - Converter tabela Parquet para Iceberg\n",
    "# Criar tabela Parquet\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE lab.db.parquet_table_parquet (\n",
    "    id INT,\n",
    "    nome STRING\n",
    ") USING PARQUET\n",
    "\"\"\")\n",
    "# Inserir dados na tabela Parquet\n",
    "spark.sql(\"INSERT INTO lab.db.parquet_table_parquet VALUES (1,'Teste1'), (2,'Teste2')\")\n",
    "# Converter para Iceberg\n",
    "spark.sql(\"ALTER TABLE lab.db.parquet_table_parquet SET TBLPROPERTIES ('format-version'='2')\")\n",
    "\n",
    "# Célula 18: Exercício 17 - Leitura incremental (Time Travel)\n",
    "# Para garantir versão, fazemos uma atualização\n",
    "spark.sql(\"UPDATE lab.db.vendas SET valor = valor + 10 WHERE ano = 2022\")\n",
    "spark.sql(\"SELECT * FROM lab.db.vendas VERSION AS OF 1\").show()\n",
    "\n",
    "# Célula 19: Exercício 18 - Exportar tabela Iceberg para CSV\n",
    "df_vendas = spark.table(\"lab.db.vendas\")\n",
    "df_vendas.write.mode(\"overwrite\").csv(\"hdfs://namenode:9000/export/vendas.csv\", header=True)\n",
    "\n",
    "# Célula 20: Exercício 19/20 - Dashboard / Trino (anotação)\n",
    "\"\"\"\n",
    "Exercício 19: Criar Dashboard no Superset\n",
    "- Adicionar banco Trino\n",
    "- Conectar ao catálogo Iceberg\n",
    "- Criar visualização\n",
    "\n",
    "Exercício 20: Ler tabela Iceberg via Trino\n",
    "- SELECT * FROM iceberg.lab.db.pessoas;\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
